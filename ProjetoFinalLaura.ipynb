{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce0e8d3-4c53-4a8f-b872-782fed18eeac",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "      ¬´ ‚ú¶ ‚Äî‚ãÜ‚Äî‚Äî‚Äï Íí∞‡¶å¬∑‚ú¶¬∑‡ªíÍí± ‚Äî‚Äî‚Äî‚ãÜ‚Äî ‚ú¶ ¬ª\n",
    "</div>\n",
    "\n",
    " \n",
    "<div style=\"text-align: center;\">\n",
    "<h1>Projeto final de Machine Learning</h1>\n",
    "<h3> TRIO EPISTASIA - Bruna Guedes, Laura Medeiros e Mariana Melo</h2>\n",
    "</div>\n",
    " \n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "      ¬´ ‚ú¶ ‚Äî‚ãÜ‚Äî‚Äî‚Äï Íí∞‡¶å¬∑‚ú¶¬∑‡ªíÍí± ‚Äî‚Äî‚Äî‚ãÜ‚Äî ‚ú¶ ¬ª\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b331d50-b119-4e82-889c-cf437a9b5719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7799dbf-be26-435c-9959-6850430535be",
   "metadata": {},
   "source": [
    "#### Sum√°rio\n",
    " \n",
    "1) Introdu√ß√£o\n",
    "1) Pr√© processamento\n",
    "2) Instancia√ß√£o dos modelos e investiga√ß√£o dos conjuntos de hiperparametros\n",
    "4) Compara√ß√£o dos algoritmos com valida√ß√£o cruzada\n",
    "5) Uso de ferramenta de explica√ß√£o de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c2ea2b-5797-484b-a17d-db2c6e9769c5",
   "metadata": {},
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f5108-7158-42b9-9455-bf580f4d5996",
   "metadata": {},
   "source": [
    "# 1. Introdu√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb0cb0-12bc-4e14-9750-f57b7f1d8b20",
   "metadata": {},
   "source": [
    "## üßë‚Äçüíª Vamos, ent√£o, para o C√≥digo M√°gico?\n",
    "\n",
    "O C√≥digo M√°gico, capaz de resolver o desafio proposto, ser√° constru√≠do a partir da linguagem Python, em conjunto com as suas bibliotecas `scikit-learn`, `xgboost`, `pandas` e `numpy`. O primeiro passo ser√°, ent√£o, importar essas bibliotecas para o nosso ambiente de programa√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f547e8-e8b3-4943-b026-558f8e34a7b3",
   "metadata": {},
   "source": [
    "# 2. Revis√£o te√≥rica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc809513-d287-47a7-ae8e-54c10085b83f",
   "metadata": {},
   "source": [
    "# 3. Metodologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac4f3c6-d454-4bd5-9fc8-d9a33806c3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1374bdb-ff0f-43c3-a167-94be1d0bcc67",
   "metadata": {},
   "source": [
    "# 4. Desenvolvimento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89978811-289b-466c-b7a1-78bff74ea8cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.1 Importa√ß√£o das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43676b46-1345-4def-aec0-e1952dae15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6bc9a6-b98d-4de3-875c-c9bfbeee7430",
   "metadata": {},
   "source": [
    "Vamos entender o que cada uma dessas bibliotecas faz?\n",
    "\n",
    "* `pandas`: utilizada para a manipula√ß√£o e organiza√ß√£o dos dados em estruturas do tipo DataFrame, que permitem opera√ß√µes semelhantes √†s de planilhas, facilitando a sele√ß√£o de atributos, filtragem de exemplos e prepara√ß√£o dos dados para os modelos.\n",
    "\n",
    "* `NumPy`: respons√°vel por opera√ß√µes num√©ricas eficientes, base para diversos c√°lculos matriciais e estat√≠sticos. Sua utiliza√ß√£o √© essencial para lidar com arrays e fornecer suporte matem√°tico √†s demais bibliotecas.\n",
    "\n",
    "* `train_test_split` (scikit-learn): m√©todo empregado para dividir o conjunto de dados em subconjuntos de treino e teste, garantindo uma avalia√ß√£o justa do desempenho dos algoritmos de aprendizado de m√°quina.\n",
    "\n",
    "* `StandardScaler` √© usado para padronizar features ao remover a m√©dia e dimensionando para a vari√¢ncia. Esse processo tamb√©m √© conhecido como normaliza√ß√£o z-score [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65283bec-b3de-4230-b28d-548462a291ea",
   "metadata": {},
   "source": [
    "A segunda etapa consiste em obter os dados a serem considerados para nosso estudo. Para nos ajudar nessa miss√£o, o Mestre C4SS4R disponibilizou um grim√≥rio m√°gico (tamb√©m conhecido como dataset `Glioma Grading Clinical and Mutation Features`). Vamos, ent√£o, carregar os dados desse dataset a partir do c√≥digo abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673cfb37-646c-43d7-a703-e7a7fa0cc988",
   "metadata": {},
   "source": [
    "## 4.2 Pr√©-processamento "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cac784-7754-4bc8-88c2-d486ccb5e305",
   "metadata": {},
   "source": [
    "O pr√©-processamento √© uma etapa cr√≠tica para a previs√£o de dados. Ele consiste em uma s√©rie de transforma√ß√µes aplicadas aos dados originais que os tornem mais limpos, adequados e otimizados, garantindo que as previs√µes feitas a partir deles tenham a maior acur√°cia poss√≠vel. Esse tratamento pode consistir em remover dados de baixa qualidade/irrelevantes, converter dados para melhor entendimento do algoritmo, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e7dedc-ab34-4c77-a4e2-9726aab45309",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2.1 Obten√ß√£o dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd9a1fb-a6ca-4eee-a16a-a22f40e541e1",
   "metadata": {},
   "source": [
    "O conjunto de dados de `Glioma Grading Clinical and Mutation Features` cont√©m 839 exemplos e 23 atributos reais, categoricos ou inteiros. Neste conjunto de dados, os 20 genes mutados com mais frequ√™ncia e 3 caracter√≠sticas cl√≠nicas s√£o considerados dos projetos de glioma cerebral TCGA-LGG e TCGA-GBM. A tarefa de previs√£o √© determinar se um paciente √© LGG ou GBM com determinadas caracter√≠sticas cl√≠nicas e moleculares/muta√ß√£o. O objetivo principal √© encontrar o subconjunto ideal de genes de muta√ß√£o e caracter√≠sticas cl√≠nicas para o processo de classifica√ß√£o do glioma para melhorar o desempenho e reduzir custos [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f8829b-5ccc-4bb3-8972-dfffcf857729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame apenas com linhas onde todos os valores s√£o non-null:\n",
      "     Grade  Gender  Age_at_diagnosis  Race  IDH1  TP53  ATRX  PTEN  EGFR  CIC  \\\n",
      "0        0       0             51.30     0     1     0     0     0     0    0   \n",
      "1        0       0             38.72     0     1     0     0     0     0    1   \n",
      "2        0       0             35.17     0     1     1     1     0     0    0   \n",
      "3        0       1             32.78     0     1     1     1     0     0    0   \n",
      "4        0       0             31.51     0     1     1     1     0     0    0   \n",
      "..     ...     ...               ...   ...   ...   ...   ...   ...   ...  ...   \n",
      "834      1       1             77.89     0     0     0     0     1     0    0   \n",
      "835      1       0             85.18     0     0     1     0     1     0    0   \n",
      "836      1       1             77.49     0     0     1     0     1     0    0   \n",
      "837      1       0             63.33     0     0     1     0     0     0    0   \n",
      "838      1       0             76.61     1     0     0     0     0     0    0   \n",
      "\n",
      "     ...  FUBP1  RB1  NOTCH1  BCOR  CSMD3  SMARCA4  GRIN2A  IDH2  FAT4  PDGFRA  \n",
      "0    ...      1    0       0     0      0        0       0     0     0       0  \n",
      "1    ...      0    0       0     0      0        0       0     0     0       0  \n",
      "2    ...      0    0       0     0      0        0       0     0     0       0  \n",
      "3    ...      0    0       0     0      0        0       0     0     1       0  \n",
      "4    ...      0    0       0     0      0        0       0     0     0       0  \n",
      "..   ...    ...  ...     ...   ...    ...      ...     ...   ...   ...     ...  \n",
      "834  ...      0    0       0     0      0        0       0     0     0       0  \n",
      "835  ...      0    0       0     0      0        0       0     0     0       0  \n",
      "836  ...      0    0       0     0      0        0       0     0     0       0  \n",
      "837  ...      0    1       0     0      0        0       0     0     0       0  \n",
      "838  ...      0    0       0     0      0        0       0     0     0       0  \n",
      "\n",
      "[839 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"TCGA_InfoWithGrade.csv\")\n",
    "\n",
    "#PR√â-PROCESSAMENTO\n",
    "\n",
    "# Selecionar linhas onde todos os valores s√£o n√£o-nulos\n",
    "df_non_null_all = df[df.notnull().all(axis=1)]\n",
    "print(\"\\nDataFrame apenas com linhas onde todos os valores s√£o non-null:\")\n",
    "print(df_non_null_all)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c7e6f-d029-4cbe-a799-cf6a30e422e3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2.2 Tipos dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c17d55c-25b2-429a-b60b-140245c0338b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grade                 int64\n",
       "Gender                int64\n",
       "Age_at_diagnosis    float64\n",
       "Race                  int64\n",
       "IDH1                  int64\n",
       "TP53                  int64\n",
       "ATRX                  int64\n",
       "PTEN                  int64\n",
       "EGFR                  int64\n",
       "CIC                   int64\n",
       "MUC16                 int64\n",
       "PIK3CA                int64\n",
       "NF1                   int64\n",
       "PIK3R1                int64\n",
       "FUBP1                 int64\n",
       "RB1                   int64\n",
       "NOTCH1                int64\n",
       "BCOR                  int64\n",
       "CSMD3                 int64\n",
       "SMARCA4               int64\n",
       "GRIN2A                int64\n",
       "IDH2                  int64\n",
       "FAT4                  int64\n",
       "PDGFRA                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_null_all.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0b49c5-b666-40ec-9837-d0fe42354f20",
   "metadata": {},
   "source": [
    "Apenas uma das colunas do dataset √© num√©rica: `Age_at_diagnosis`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36326b9b-f004-471d-81e3-1d6dfff2ab5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2.3 Escolha do target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc219635-02d4-4049-8e03-7b4fcf6b5e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [col for col in df_non_null_all.columns if col != 'Grade']\n",
    "TARGET = ['Grade']\n",
    "\n",
    "X = df_non_null_all[FEATURES]\n",
    "y = df_non_null_all[TARGET]\n",
    "\n",
    "X = X.values\n",
    "y = y.values.ravel()  # o m√©todo `ravel` deixa os dados em 1 dimens√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a786e-a597-416f-91fc-5ddc6d5c9a8e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.2.4 Separa√ß√£o de dados de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314c6f4a-4228-4511-81af-f4cea1fd3074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de dados para treino: 587\n",
      "N√∫mero de dados para teste: 252\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "#Standard\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "X_train_scaled_standard = scaler_standard.fit_transform(X_train)\n",
    "X_test_scaled_standard = scaler_standard.transform(X_test)\n",
    "\n",
    "print (\"N√∫mero de dados para treino:\", len(X_train_scaled_standard))\n",
    "print (\"N√∫mero de dados para teste:\", len(X_test_scaled_standard))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a65d15-763f-41a8-92da-8ab5a623f487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.3 Instancia√ß√£o dos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dad0bb-f2e2-4562-b77d-0b244c970b2d",
   "metadata": {},
   "source": [
    "Tendo nossos dados preparados com target e features delimitados, podemos prosseguir para as etapas de instanciamento, previs√£o e valida√ß√£o dos modelos preditivos. Para esse projeto, escolhemos trabalhar com os cinco modelos abaixo: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5246a9-9caa-4bfe-bcf8-ccc7b1ace3fc",
   "metadata": {},
   "source": [
    "- RandomForestClassifier \n",
    "- GradientBoostClassifier (XGBoost)\n",
    "- SupportVectorClassifier (SVC)\n",
    "- Bernoulli NaiveBayes (NB)\n",
    "- ExtraTreesClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382261ca-4f56-472d-9c6e-ae0c8980c124",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3.1 RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9e0c79-56b2-4afc-b4c6-e4a1a7cc4d26",
   "metadata": {},
   "source": [
    "O `RandomForestClassifier` realiza previs√µes por meio da cria√ß√£o de m√∫ltiplas **√°rvores de decis√£o**. Uma √°rvore de decis√£o segue uma estrutura semelhante a de um fluxograma, onde cada ramo (chamado de *n√≥ de decis√£o*) simboliza um condicional. A cria√ß√£o dessas √°rvores envolve uma subamostra e um subconjunto de tributos aleat√≥rios. Cada √°rvore √©, portanto, exposta a um n√∫mero diferente de recursos e a uma amostra diferente do conjunto de dados original [3], o que garante que uma √∫nica √°rvore n√£o se atenha demais a um √∫nico subconjunto espec√≠fico de dados, o que prejudicaria na acur√°cia das previs√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c01e416-5ff8-447d-a767-fa740e7a43fc",
   "metadata": {},
   "source": [
    "Quando novos dados s√£o apresentados ao modelo (nesse caso, um novo paciente com caracter√≠sticas singulares a respeito da idade e concentra√ß√£o de prote√≠nas), ele √© processado por todas as √°rvores de decis√£o individualmente. Cada √°rvore decide qual ser√° o r√≥tulo (LGG ou GBM), e ao final, o algoritmo considera a categoria com maior n√∫mero de votos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad869f7c-2e80-47cc-aa75-6af29b9e7047",
   "metadata": {},
   "source": [
    "Esse modelo toma como hiperpar√¢metros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "468ea55c-6205-4ac7-98fd-bb3688542358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier() \n",
    "\n",
    "random_forest.fit(X_train_scaled_standard, y_train)\n",
    "\n",
    "previsao_RF = random_forest.predict(X_test_scaled_standard)\n",
    "\n",
    "previsao_RF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de369084-bf66-4a48-bf3c-51f16bd928c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3.2 XGBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bace8f8-054f-4cc3-942e-75b7b55c7126",
   "metadata": {},
   "source": [
    "O **Gradient Boosting** √© uma forma de algoritmo que se beneficia do uso de uma equipe de outros modelos simples (geramente √°rvores de decis√£o) para prever dados. Em suas previs√µes, ele primeiro realiza um chute inicial simples (tirando a m√©dia ou moda, por exemplo), para ent√£o calcular os erros. Ele ent√£o treina modelos simples para tentar prever e compreender os erros que esse modelo inicial realizou, somando essa corre√ß√£o ao chute inicial e realizando uma nova previs√£o. Esse processo √© repetido v√°rias vezes, at√© que os erros sejam minimizados ao m√°ximo. Isso lhe da um controle excelente sobre problemas de *overfitting*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabf8f3e-c4b1-4047-bc77-7d49fedd698c",
   "metadata": {},
   "source": [
    "O `XGBoost` (Extreme Gradient Boosting) √© uma vers√£o otimizada desse algoritmo, implementando melhorias que o tornam mais preciso, como a regulariza√ß√£o L1 e L2, que adiciona uma penalidade para modelos que se demonstram muito apegados a um conjunto espec√≠fico dos dados e poderia gerar previs√µes \"viciadas\". Usamos o `XGBoostClassifier` para problemas de classifica√ß√£o, como √© o nosso caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d5dd7d-26ca-4526-8bcd-8eb321000214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost = XGBClassifier()\n",
    "\n",
    "xgboost.fit(X_train_scaled_standard, y_train)\n",
    "\n",
    "previsao_XGB = xgboost.predict(X_test_scaled_standard)\n",
    "\n",
    "previsao_XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba16a7-7f73-4813-aa79-3e4a7a60267e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3.3 SupportVectorClassification (SVC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5880f9e2-495c-49eb-9418-d808a3569f4e",
   "metadata": {},
   "source": [
    "O algoritmo `SupportVectorClassification` √© uma modalidade do `SupportVectorMachine` (SVM). Ele busca manter r√≥tulos diferentes o mais distantes poss√≠veis - ou seja, ele tenta separar e maximizar a margem entre os dados da melhor maneira poss√≠vel, tornando-os dist√≠nguiveis o suficiente para uma previs√£o com boa acur√°cia. Os pontos mais pr√≥ximos entre a margem que divide os dados s√£o chamados de **vetores de suporte**, o que justifica o nome do algoritmo. O SVC obt√™m um espa√ßo onde a divis√£o √© pode ser realizada por meio de um plano, utilizando a t√©nica **Kernel**: ele transforma os dados para um espa√ßo de maior dimens√£o (3D ou mais), assim conseguindo separar os dados linearmente. O SVC ent√£o calcula o **produto escalar** para definir o Hiperplano de Separa√ß√£o (fronteira de decis√£o). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad84479-da45-41d8-bc21-03d58c7ab278",
   "metadata": {},
   "source": [
    "Sendo um classificador discriminativo, ele √© ideal para problemas de classifica√ß√£o bin√°ria, e portanto podemos aplic√°-lo para o nosso caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfb27b6-3a13-48c3-8a2d-f9e9fa1ac283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC = SVC()\n",
    "\n",
    "SVC.fit(X_train_scaled_standard, y_train)\n",
    "\n",
    "previsao_SVC = SVC.predict(X_test_scaled_standard)\n",
    "\n",
    "previsao_SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f4c4a0-7f86-444b-a46b-186113ac6ba3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3.4 Bernoulli NaiveBayes (NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c93e9d-5ce8-4f15-bfa2-c37a2e901e99",
   "metadata": {},
   "source": [
    "O classificador Naive Bayes (NB) √© um algoritmo de aprendizado de m√°quina que se baseia no **Teorema de Bayes** para realizar classifica√ß√µes. Ele calcula a **probabilidade a posteriori** de cada classe, dadas as caracter√≠sticas de um novo dado. O algoritmo ent√£o atribui o dado √† classe com a maior probabilidade. O Teorema de Bayes √© dado pela equa√ß√£o:\n",
    "\n",
    "$$\n",
    "P(A | B) = \\frac{P(A) P(B | A).}{P(B)}.\n",
    "$$\n",
    "*(Onde $P(A)$ √© a probabilidade inicial; $P(B|A)$ √© a verossimilhan√ßa (probabilidade de $A$ dado que $B$ ocorreu); $P(B)$ √© a probabilidade individual (tamb√©m chamada de evid√™ncia); e $P(A|B)$ √© a probabilidade a posteriori)*\n",
    "\n",
    "O termo \"Naive\" (Ing√™nuo) vem da principal simplifica√ß√£o que o algoritmo faz: ele assume que todas as caracter√≠sticas (features) s√£o condicionalmente independentes umas das outras. Essa suposi√ß√£o, entre tanto, o torna um algoritmo muito funcional para previs√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2897aefc-3144-4afe-a777-474e250d8310",
   "metadata": {},
   "source": [
    "O `Bernoulli NaiveBayes` √© uma variante desse classificador que analisa a presen√ßa ou aus√™ncia de uma *feature* - sendo melhor aplicado quando os dados est√£o em sua forma bin√°ria (0 ou 1). Em nosso dataset, ele calcula a probabilidade de cada classe dado a presen√ßa ou aus√™ncia das muta√ß√µes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4456d2c1-ea6b-4987-8f2a-15ab076ec678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "\n",
    "BNB.fit(X_train_scaled_standard, y_train)\n",
    "\n",
    "previsao_BNB = BNB.predict(X_test_scaled_standard)\n",
    "\n",
    "previsao_BNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27dda0a-2dc9-4b5b-a16f-2eae939f7f63",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4.3.5 ExtraTreesClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132e77b0-d71c-45c9-8940-5edd8c7fc375",
   "metadata": {},
   "source": [
    "O `ExtraTreesClassifier` (Extremely Randomized Trees) segue a mesma premissa do `RandomForestClassifier`, como discutido anteriormente, por√©m, possui caracteristicas que ajudam a minimizar ainda mais o overfitting e ajudar na generaliza√ß√£o. A principal delas √© que ele introduz mais aleatoriedade, tornando as √°rvores mais diversas ao tamb√©m randomizar o split de dados (diferente do RFC, que escolhe o melhor ponto de corte usando m√©tricas como Entropia). Devido a esse fato, ele tamb√©m pode executar de forma bem mais r√°pida comparado ao RFC tradicional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "914024b5-ba91-4537-8afc-2f33971d0b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ETC = ExtraTreesClassifier()\n",
    "\n",
    "ETC.fit(X_train_scaled_standard, y_train)\n",
    "\n",
    "previsao_ETC = ETC.predict(X_test_scaled_standard)\n",
    "\n",
    "previsao_ETC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e08e7-a185-4c0f-94fb-6f53851a5ad3",
   "metadata": {},
   "source": [
    "# Resultados e Discuss√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5799a369-0d12-4af1-9cc7-3a218c329aab",
   "metadata": {},
   "source": [
    "# Conclus√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0f9e2-25a2-468f-9bc3-6e4833724a38",
   "metadata": {},
   "source": [
    "# Refer√™ncias Bibliogr√°ficas\n",
    "\n",
    "[1] SCIKIT-LEARN. StandardScaler. Dispon√≠vel em: <https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html>.\n",
    "\n",
    "[2] UCI Machine Learning Repository. Dispon√≠vel em: <https://archive.ics.uci.edu/dataset/759/glioma+grading+clinical+and+mutation+features+dataset>.\n",
    "\n",
    "[3] https://www.datacamp.com/pt/tutorial/random-forests-classifier-python\n",
    "\n",
    "https://www.datacamp.com/pt/tutorial/guide-to-the-gradient-boosting-algorithm\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
